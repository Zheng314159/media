#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
make_subtitle.py - è‡ªåŠ¨ä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•å¹¶çƒ§å½•åˆ°è§†é¢‘ä¸­
ä¾èµ–:
    pip install faster-whisper ffmpeg-python opencc-python-reimplemented
è¿˜éœ€è¦æœ¬åœ°å®‰è£… ffmpeg: https://ffmpeg.org/download.html

ç”¨æ³•:
    python make_subtitle.py input.mp4
"""

import os
import subprocess
import sys
import json
from pathlib import Path
from faster_whisper import WhisperModel
from opencc import OpenCC

# ======================
# é…ç½®åŠ è½½
# ======================
BASE_DIR = Path(__file__).resolve().parent
CONFIG_PATH = BASE_DIR / "config.json"

DEFAULT_CONFIG = {
    "ffmpeg_path": r"F:\media\external_libs\ffmpeg\bin\ffmpeg.exe",
    "model_dir": str(BASE_DIR.parent / "models" / "faster-whisper-small"),
    "simplified": True,         # æ˜¯å¦è½¬ä¸ºç®€ä½“ä¸­æ–‡
    "fontsize": 30,             # å­—å¹•å­—å·
    "fontname": "SimHei"        # å­—ä½“åç§°
}

if CONFIG_PATH.exists():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        CONFIG = json.load(f)
else:
    CONFIG = DEFAULT_CONFIG
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(DEFAULT_CONFIG, f, indent=4, ensure_ascii=False)
    print(f"âš ï¸ æœªæ‰¾åˆ° config.jsonï¼Œå·²ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶: {CONFIG_PATH}")


def format_timestamp(seconds: float) -> str:
    """è½¬ä¸º SRT æ—¶é—´æˆ³æ ¼å¼ 00:00:00,000"""
    milliseconds = int((seconds - int(seconds)) * 1000)
    seconds = int(seconds)
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"


def extract_audio(video_path: str, audio_path: str):
    """æå–å•å£°é“ 16kHz éŸ³é¢‘"""
    cmd = [
        CONFIG["ffmpeg_path"], "-y",
        "-i", video_path,
        "-ar", "16000",
        "-ac", "1",
        audio_path
    ]
    subprocess.run(cmd, check=True)


def generate_srt(audio_path: str, srt_path: str):
    """è°ƒç”¨ faster-whisper ç”Ÿæˆå­—å¹•æ–‡ä»¶"""
    model = WhisperModel(CONFIG["model_dir"], device="cpu")

    cc = OpenCC("t2s") if CONFIG.get("simplified", False) else None

    segments, info = model.transcribe(
        audio_path,
        beam_size=5,
        task="transcribe",
        language="zh"
    )

    with open(srt_path, "w", encoding="utf-8") as f:
        for i, seg in enumerate(segments, 1):
            start = format_timestamp(seg.start)
            end = format_timestamp(seg.end)
            text = seg.text.strip()
            if cc:
                text = cc.convert(text)
            f.write(f"{i}\n{start} --> {end}\n{text}\n\n")

    print(f"âœ… å·²ç”Ÿæˆå­—å¹•æ–‡ä»¶: {srt_path}")


def burn_subtitles(video_path: str, srt_path: str, output_path: str):
    """ç”¨ ffmpeg çƒ§å½•å­—å¹•"""
    style = f"FontName={CONFIG['fontname']},Fontsize={CONFIG['fontsize']}"
    cmd = [
        CONFIG["ffmpeg_path"], "-y",
        "-i", video_path,
        "-vf", f"subtitles={srt_path}:force_style='{style}'",
        output_path
    ]
    subprocess.run(cmd, check=True)
    print(f"ğŸ¬ å·²è¾“å‡ºå¸¦å­—å¹•è§†é¢‘: {output_path}")


def main():
    os.makedirs("outputs", exist_ok=True)
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python make_subtitle.py <è§†é¢‘æ–‡ä»¶>")
        sys.exit(1)

    video_file = sys.argv[1]
    base = Path(video_file).stem
    audio_file = f"outputs/{base}_audio.wav"
    srt_file = f"outputs/{base}.srt"
    out_file = f"outputs/{base}_subtitled.mp4"

    extract_audio(video_file, audio_file)
    generate_srt(audio_file, srt_file)
    burn_subtitles(video_file, srt_file, out_file)


if __name__ == "__main__":
    main()
