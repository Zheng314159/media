#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
make_subtitle.py - è‡ªåŠ¨ä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•å¹¶çƒ§å½•åˆ°è§†é¢‘ä¸­ï¼ˆæ”¯æŒæ‰‹åŠ¨ä¿®æ”¹åå†åˆå¹¶çš„ä¸­è‹±åŒè¯­æµç¨‹ï¼‰

ä¾èµ–:
    pip install faster-whisper ffmpeg-python opencc-python-reimplemented
è¿˜éœ€è¦æœ¬åœ°å®‰è£… ffmpeg: https://ffmpeg.org/download.html

ç”¨æ³•ï¼ˆé€æ­¥ï¼‰:
  1) æå–éŸ³é¢‘:
     python make_subtitle.py extract <video.mp4>
     -> ç”Ÿæˆ <video>_audio.wav

  2) ç”Ÿæˆä¸­æ–‡å­—å¹•ï¼ˆå¯é€‰ç®€ä½“è½¬æ¢ï¼Œç”Ÿæˆåå¯æ‰‹åŠ¨ä¿®æ”¹ï¼‰:
     python make_subtitle.py gen-zh <video>_audio.wav
     -> ç”Ÿæˆ <video>_zh.srt

  3) ç”Ÿæˆè‹±æ–‡å­—å¹•ï¼ˆè‹±æ–‡ç¿»è¯‘ï¼‰:
     python make_subtitle.py gen-en <video>_audio.wav
     -> ç”Ÿæˆ <video>_en.srt

  4) ï¼ˆå¯é€‰ï¼‰æ‰‹åŠ¨æ‰“å¼€ <video>_zh.srt ä¿®æ”¹ä¸­æ–‡å†…å®¹ï¼Œä½†**ä¸è¦æ”¹åŠ¨æ—¶é—´è½´**æ›´ç¨³å¦¥

  5) åˆå¹¶ä¸­è‹±ä¸ºåŒè¯­ SRTï¼ˆä¸­æ–‡åœ¨ä¸Šï¼Œè‹±æ–‡åœ¨ä¸‹ï¼‰:
     python make_subtitle.py merge <video>_zh.srt <video>_en.srt
     -> ç”Ÿæˆ <video>_bi.srt

  6) çƒ§å½•åŒè¯­å­—å¹•åˆ°è§†é¢‘:
     python make_subtitle.py burn <video.mp4> <video>_bi.srt
     -> ç”Ÿæˆ <video>_subtitled.mp4
"""

import re
import subprocess
import sys
import json
from pathlib import Path
from typing import List, Tuple, Optional
from faster_whisper import WhisperModel
from opencc import OpenCC

# ======================
# é…ç½®åŠ è½½
# ======================
BASE_DIR = Path(__file__).resolve().parent
CONFIG_PATH = BASE_DIR / "config.json"

DEFAULT_CONFIG = {
    "ffmpeg_path": r"F:\media\external_libs\ffmpeg\bin\ffmpeg.exe",
    "model_dir": str(BASE_DIR.parent / "models" / "faster-whisper-small"),
    "simplified": True,         # æ˜¯å¦æŠŠä¸­æ–‡å­—å¹•è½¬ä¸ºç®€ä½“ä¸­æ–‡
    "fontsize": 30,             # å­—å¹•å­—å·ï¼ˆSRT å…¨éƒ¨ç»Ÿä¸€å¤§å°ï¼‰
    "fontname": "SimHei"        # å­—ä½“åç§°
}

if CONFIG_PATH.exists():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        CONFIG = json.load(f)
else:
    CONFIG = DEFAULT_CONFIG
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(DEFAULT_CONFIG, f, indent=4, ensure_ascii=False)
    print(f"âš ï¸ æœªæ‰¾åˆ° config.jsonï¼Œå·²ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶: {CONFIG_PATH}")


# ======================
# æ—¶é—´æˆ³å·¥å…·
# ======================
def format_timestamp(seconds: float) -> str:
    """è½¬ä¸º SRT æ—¶é—´æˆ³æ ¼å¼ 00:00:00,000"""
    milliseconds = int(round((seconds - int(seconds)) * 1000))
    seconds = int(seconds)
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"


def parse_timestamp(ts: str) -> float:
    """SRT æ—¶é—´æˆ³ 00:00:00,000 -> ç§’"""
    h, m, rest = ts.split(":")
    s, ms = rest.split(",")
    return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000.0


# ======================
# SRT è¯»å†™
# ======================
class SRTEntry:
    def __init__(self, idx: int, start: float, end: float, text: str):
        self.idx = idx
        self.start = start
        self.end = end
        self.text = text  # å…è®¸å¤šè¡Œ


def read_srt(path: str) -> List[SRTEntry]:
    content = Path(path).read_text(encoding="utf-8", errors="ignore")
    # å»æ‰ UTF-8 BOM
    content = content.lstrip("\ufeff")
    blocks = re.split(r"\n{2,}", content.strip())
    entries: List[SRTEntry] = []
    for b in blocks:
        lines = [ln for ln in b.splitlines() if ln.strip() != "" or True]
        if len(lines) < 2:
            continue
        # ç¬¬ä¸€è¡Œå¯èƒ½æ˜¯åºå·
        idx_line = lines[0].strip()
        idx = None
        if re.fullmatch(r"\d+", idx_line):
            idx = int(idx_line)
            time_line_i = 1
        else:
            # æ²¡æœ‰åºå·çš„ SRTï¼ˆå°‘è§ï¼‰ï¼Œå°è¯•ä»è¡Œ0è¯»å–æ—¶é—´
            time_line_i = 0
            idx = len(entries) + 1

        time_line = lines[time_line_i].strip()
        m = re.match(r"(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})", time_line)
        if not m:
            continue
        start = parse_timestamp(m.group(1))
        end = parse_timestamp(m.group(2))

        text_lines = lines[time_line_i + 1 :]
        text = "\n".join(text_lines).strip()
        entries.append(SRTEntry(idx, start, end, text))
    return entries


def write_srt(entries: List[SRTEntry], path: str):
    with open(path, "w", encoding="utf-8") as f:
        for i, e in enumerate(entries, 1):
            f.write(f"{i}\n{format_timestamp(e.start)} --> {format_timestamp(e.end)}\n{e.text}\n\n")


# ======================
# å½±éŸ³å¤„ç†
# ======================
def extract_audio(video_path: str, audio_path: str):
    """æå–å•å£°é“ 16kHz éŸ³é¢‘"""
    cmd = [
        CONFIG["ffmpeg_path"], "-y",
        "-i", video_path,
        "-ar", "16000",
        "-ac", "1",
        audio_path
    ]
    subprocess.run(cmd, check=True)
    print(f"ğŸ§ å·²æå–éŸ³é¢‘: {audio_path}")


# ======================
# æ¨¡å‹è°ƒç”¨ï¼ˆç‹¬ç«‹æ­¥éª¤ï¼‰
# ======================
def load_model() -> WhisperModel:
    return WhisperModel(CONFIG["model_dir"], device="cpu")


def generate_zh_srt(audio_path: str, zh_srt_path: str, language: str = "zh"):
    """ç”Ÿæˆä¸­æ–‡å­—å¹•ï¼ˆå¯æŒ‰é…ç½®è½¬ç®€ä½“ï¼‰ï¼Œä»…ä¸­æ–‡ä¸€è¡Œ"""
    model = load_model()
    cc = OpenCC("t2s") if CONFIG.get("simplified", False) else None

    segments, _ = model.transcribe(
        audio_path,
        beam_size=5,
        task="transcribe",
        language=language
    )

    entries: List[SRTEntry] = []
    for i, seg in enumerate(segments, 1):
        text = seg.text.strip()
        if cc:
            text = cc.convert(text)
        entries.append(SRTEntry(i, seg.start, seg.end, text))

    write_srt(entries, zh_srt_path)
    print(f"âœ… å·²ç”Ÿæˆä¸­æ–‡å­—å¹•: {zh_srt_path}")


def generate_en_srt(audio_path: str, en_srt_path: str, source_language: str = "zh"):
    """ç”Ÿæˆè‹±æ–‡å­—å¹•ï¼ˆWhisper ç¿»è¯‘ï¼‰ï¼Œä»…è‹±æ–‡ä¸€è¡Œ"""
    model = load_model()
    segments, _ = model.transcribe(
        audio_path,
        beam_size=5,
        task="translate",
        language=source_language
    )

    entries: List[SRTEntry] = []
    for i, seg in enumerate(segments, 1):
        text = seg.text.strip()
        entries.append(SRTEntry(i, seg.start, seg.end, text))

    write_srt(entries, en_srt_path)
    print(f"âœ… å·²ç”Ÿæˆè‹±æ–‡å­—å¹•: {en_srt_path}")


# ======================
# åˆå¹¶ï¼ˆç‹¬ç«‹æ­¥éª¤ï¼‰
# ======================
def align_segments_by_time(
    zh: List[SRTEntry],
    en: List[SRTEntry],
    tolerance: float = 1.0
) -> List[Tuple[SRTEntry, Optional[SRTEntry]]]:
    """
    å°†ä¸­æ–‡æ®µè½ä¸è‹±æ–‡æ®µè½æŒ‰èµ·å§‹æ—¶é—´è¿‘ä¼¼å¯¹é½ã€‚
    - ä¼˜å…ˆä¸€ä¸€é…å¯¹ï¼ˆé¿å…é‡å¤ä½¿ç”¨è‹±æ–‡æ¡ç›®ï¼‰
    - è‹¥æ‰¾ä¸åˆ°åˆé€‚è‹±æ–‡ï¼Œè‹±æ–‡ä¸º Noneï¼ˆä¼šåªè¾“å‡ºä¸­æ–‡è¡Œï¼‰
    æç¤ºï¼šå¦‚æœä½ æ²¡æœ‰æ”¹åŠ¨ä¸­æ–‡å­—å¹•çš„æ—¶é—´è½´ï¼Œé€šå¸¸é•¿åº¦ä¸€è‡´ï¼Œæ­¤æ­¥éª¤åªæ˜¯å…œåº•ã€‚
    """
    result: List[Tuple[SRTEntry, Optional[SRTEntry]]] = []
    used = [False] * len(en)
    j = 0
    for z in zh:
        best_idx = None
        best_diff = float("inf")
        # é™åˆ¶æœç´¢çª—å£æé«˜é€Ÿåº¦
        for k in range(j, min(j + 10, len(en))):
            if used[k]:
                continue
            diff = abs(en[k].start - z.start)
            if diff < best_diff:
                best_diff = diff
                best_idx = k
                if best_diff <= tolerance:
                    break
        if best_idx is not None:
            result.append((z, en[best_idx]))
            used[best_idx] = True
            j = best_idx + 1
        else:
            result.append((z, None))
    return result


def merge_bilingual_srt(zh_srt_path: str, en_srt_path: str, out_path: str):
    """
    åˆå¹¶ä¸ºåŒè¯­ SRTï¼šä¸­æ–‡åœ¨ä¸Šï¼Œè‹±æ–‡åœ¨ä¸‹ã€‚
    - é»˜è®¤æŒ‰æ—¶é—´å¯¹é½ï¼ˆæ›´ç¨³ï¼‰ï¼Œå¦‚æœæ¡ç›®æ•°é‡ä¸€è‡´ä¸”æ—¶é—´åŸºæœ¬ä¸€è‡´ï¼Œå…¶å®ç­‰ä»·äºæŒ‰ç´¢å¼•å¯¹é½ã€‚
    - å¦‚æœæŸæ¡æ²¡æœ‰è‹±æ–‡åŒ¹é…ï¼Œä¼šåªå†™ä¸­æ–‡è¡Œã€‚
    """
    zh_entries = read_srt(zh_srt_path)
    en_entries = read_srt(en_srt_path)

    pairs = align_segments_by_time(zh_entries, en_entries, tolerance=1.0)

    merged: List[SRTEntry] = []
    for i, (zh, en) in enumerate(pairs, 1):
        # é‡‡ç”¨ä¸­æ–‡æ—¶é—´è½´ä¸ºå‡†ï¼›è‹¥è‹±æ–‡å­˜åœ¨ä½†æ›´é•¿ï¼Œä½ ä¹Ÿå¯ä»¥æŒ‰éœ€æ”¹ä¸º max()
        start = zh.start
        end = zh.end
        if en is not None:
            text = f"{zh.text}\n{en.text}"
        else:
            text = zh.text
        merged.append(SRTEntry(i, start, end, text))

    write_srt(merged, out_path)
    print(f"ğŸˆ´ å·²åˆå¹¶åŒè¯­å­—å¹•: {out_path}")


# ======================
# çƒ§å½•ï¼ˆç‹¬ç«‹æ­¥éª¤ï¼‰
# ======================
def _escape_for_ffmpeg_subtitles(path: str) -> str:
    """
    å¤„ç† Windows è·¯å¾„åœ¨ subtitles æ»¤é•œä¸­çš„è½¬ä¹‰:
    - åæ–œæ  -> åŒåæ–œæ 
    - ç›˜ç¬¦å†’å· -> '\:'
    - å•å¼•å· -> '\''
    """
    p = path.replace("\\", "\\\\")
    # åªæ›¿æ¢ç›˜ç¬¦å¤„çš„å†’å·ï¼Œå¦‚ C:\  -> C\:
    if re.match(r"^[A-Za-z]:", path):
        p = p.replace(":", r"\:", 1)
    p = p.replace("'", r"\'")
    return p


def burn_subtitles(video_path: str, srt_path: str, output_path: str):
    """ç”¨ ffmpeg çƒ§å½•å­—å¹•ï¼ˆSRT ç»Ÿä¸€æ ·å¼ï¼‰"""
    style = f"FontName={CONFIG['fontname']},Fontsize={CONFIG['fontsize']}"
    srt_escaped = _escape_for_ffmpeg_subtitles(str(Path(srt_path).resolve()))
    vf = f"subtitles='{srt_escaped}':force_style='{style}'"

    cmd = [
        CONFIG["ffmpeg_path"], "-y",
        "-i", video_path,
        "-vf", vf,
        output_path
    ]
    subprocess.run(cmd, check=True)
    print(f"ğŸ¬ å·²è¾“å‡ºå¸¦å­—å¹•è§†é¢‘: {output_path}")


# ======================
# å‘½ä»¤è¡Œå…¥å£ï¼ˆæ¯ä¸€æ­¥å¯å•ç‹¬æ‰§è¡Œï¼‰
# ======================
def main():
    if len(sys.argv) < 2:
        print(__doc__)
        sys.exit(1)

    sub = sys.argv[1].lower()

    if sub == "extract":
        if len(sys.argv) < 3:
            print("ç”¨æ³•: python make_subtitle.py extract <video.mp4>")
            sys.exit(1)
        video = sys.argv[2]
        base = Path(video).with_suffix("")
        audio = f"{base}_audio.wav"
        extract_audio(video, audio)

    elif sub == "gen-zh":
        if len(sys.argv) < 3:
            print("ç”¨æ³•: python make_subtitle.py gen-zh <audio.wav>")
            sys.exit(1)
        audio = sys.argv[2]
        base = Path(audio).with_suffix("")
        zh_srt = f"{base}_zh.srt"
        generate_zh_srt(audio, zh_srt)

    elif sub == "gen-en":
        if len(sys.argv) < 3:
            print("ç”¨æ³•: python make_subtitle.py gen-en <audio.wav>")
            sys.exit(1)
        audio = sys.argv[2]
        base = Path(audio).with_suffix("")
        en_srt = f"{base}_en.srt"
        generate_en_srt(audio, en_srt)

    elif sub == "merge":
        if len(sys.argv) < 4:
            print("ç”¨æ³•: python make_subtitle.py merge <zh.srt> <en.srt>")
            sys.exit(1)
        zh_srt = sys.argv[2]
        en_srt = sys.argv[3]
        # è¾“å‡ºåæŒ‰ä¸­æ–‡ SRT å‘½å
        base = Path(zh_srt).with_suffix("")
        out = f"{base}_bi.srt"
        merge_bilingual_srt(zh_srt, en_srt, out)

    elif sub == "burn":
        if len(sys.argv) < 4:
            print("ç”¨æ³•: python make_subtitle.py burn <video.mp4> <bilingual.srt>")
            sys.exit(1)
        video = sys.argv[2]
        srt = sys.argv[3]
        base = Path(video).with_suffix("")
        out = f"{base}_subtitled.mp4"
        burn_subtitles(video, srt, out)

    else:
        print("æœªçŸ¥å‘½ä»¤ã€‚å¯ç”¨å‘½ä»¤: extract | gen-zh | gen-en | merge | burn")
        sys.exit(1)


if __name__ == "__main__":
    main()
